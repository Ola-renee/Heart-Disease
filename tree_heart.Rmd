---
title: "Predicting Heart Disease"
author: "Olachi Mbakwe, Justin Constant, Rebande Olusesi and Evan Settipane"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
geometry: left=1in,right=1in,top=1in,bottom=1in
urlcolor: blue
header-includes:
  - \usepackage{subfig}
  - \usepackage{float}
  - \usepackage{booktabs}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = "center",
	cache = TRUE
)

```

```{r packages, include=FALSE}

# Packages to install ----
## tree, rpart, rpart.plot, partykit, rattle, and randomForest
#install.packages(
 #  pkgs = c("tree", "rpart", "rpart.plot", "partykit", "rattle", "randomForest"))

# Load packages used in this guide ----
packages <- c("readr","dplyr","tidyverse", "knitr", "kableExtra","psych",
              "janitor","tree", "rpart", "rpart.plot", "partykit",
              "rattle", "randomForest", "yardstick","leaps",
              "ggplot2","pROC","separationplot")


invisible(
  lapply( 
    X = packages,
    FUN = library,
    character.only = TRUE,
    quietly = TRUE
  )
)

# Set the CRAN mirror
options(repos = "https://cran.rstudio.com/")

# Set Table Option ----
options(knitr.kable.NA = "") 


```

```{r Loading data, echo=FALSE}
heart_csvEvan <- read_csv("heart.csv")
```

# Introduction

# Engaging with Heart Data set

# Study Design and Methods

# Data Exploration

# Regression Model

## Running Algorithms

## Assessing and Evaluating the Candidate Model

# Decision Tree

Within this area of the project, because of our data set not being the biggest thing ever, we are more prone of over fitting using decision trees.

```{r train}
# Replace 0s with "No Heart Disease" and 1s with "Heart Disease" in a specific column
heart_csvEvan$HeartDisease <- ifelse(heart_csvEvan$HeartDisease == 0, "No Heart Disease", "Heart Disease")

#Build Data sets for models
modelDataEvan <-  heart_csvEvan %>%
  drop_na() %>%
  mutate(
    tempID = row_number(),
    .before = HeartDisease
  )

#Set seed for reproducibility and slice
set.seed(380)
trainingDataEvan <- modelDataEvan %>%
  group_by(HeartDisease) %>%
  slice_sample(prop = 0.8)

trainingResultsEvan <- trainingDataEvan

testingDataEvan <- modelDataEvan
```

# Testing and Predicting

```{r growrPart, fig.pos = "H"}
# Grow tree via rpart package
# library(rpart)
rpartHeart1 <- rpart(
  formula = HeartDisease ~ Sex + RestingBP + Cholesterol + ExerciseAngina + ChestPainType,
  data = trainingDataEvan,
  method = "class",
  parms = list(split = "information"),
  control = rpart.control()
)
```

```{r rpartPlot, fig.pos = "H",echo=FALSE, message=FALSE}
# Display rpart.plot
# library(rpart.plot)
rpart.plot(
  x = rpartHeart1,
  type = 2,
  extra = 101
)
```

Above is now a plot for our first rPart tree. This tree gives us insight in some good statistics about its decision making based on if a person has heart disease or not. Within each node we see two separate number's and a percentage's. We also see either "Heart Disease" or "No Heart Disease" and a color that is filled within the node. I will first start with explaining the percentage and the numbers in the nodes. The numbers are representing either a person with or without heart disease, and the percentages are representing the total number of people in that node compared to the whole data set. So if we were to look at the node with 46% in it (top right), we now know that this node has 46% of the people in the data set.

####Now for this plot to make a little more sense I will need to explain the color of the nodes and what numbers in them represent Graduated and what represent Not Graduated. Now again, looking at the 90% node we see that it is Graduated with a blue fill, and every other node with Graduated has a blue fill. This could only mean that the blue fill represents Graduated students and the green fill represents Not Graduated students. Now knowing this, we can assume that the numbers on the left in the nodes are Graduated students and the numbers on the right are Not Graduated students. The last thing we can see in this plot is that the colored fills are darker or lighter. Lets look at the two nodes on the bottom right, with 6% and 10%. When looking at the 6% node, we can see that the fill is a much lighter color than the 10% node, and while looking at the number distribution in them we can see that the 6% node is much closer to each other than the 10% node. Now with this information we can assume that the lighter the color, the less distribution there is between Not Graduated and Graduated students, while more distribution makes the fill darker.

```{r rpartTree, fig.pos = "H",echo=FALSE, message=FALSE}
# Using the rattle package to visualize the tree
fancyRpartPlot(
  model = rpartHeart1,
  main = NULL,
  sub = NULL
)
```

```{r elements}
# Get table elements
invisible(capture.output({cpTable <- printcp(rpartHeart1)}))
```

```{r cpTbl, fig.pos = "H", echo=FALSE, message=FALSE}
# Create nice looking table of CP results
kable(
  x = cpTable,
  col.names = c("CP", "Num. of splits", "Rel. Error",
                "Mean Error", "Std. Deviation of Error"),
  digits = 3,
  booktabs = TRUE,
  align = "c",
  table.attr = 'data-quarto-disable-processing="true"'
) %>%
  kable_classic(
    full_width = FALSE
  ) %>%
  kable_styling(latex_options = c("HOLD_position"))
```

```{r cpPlot, fig.pos = "H",echo=FALSE, message=FALSE}
# Plot the CP results from rpart
plotcp(
  x = rpartHeart1,
  minline = TRUE,
  upper = "size"
)
```

```{r prune}
# Prune the rpart Tree
rpartHeart2 <- prune(
  tree = rpartHeart1,
  cp = 0.011
)
```

```{r predGrad}
## The rpart package
pred_heartRpart2 <- predict(
  object = rpartHeart2,
  newdata = testingDataEvan,
  type = "prob"
)
```

```{r wrangle}
# Data Wrangling the predictions
heartPredictionsEvan <- data.frame(
  rpart2_heart = pred_heartRpart2[, 1],
  rpart2_nonHeart = pred_heartRpart2[, 2]
) %>%
  mutate(
    rpart2_pred = ifelse(
      test = rpart2_heart > rpart2_nonHeart,
      yes = "Heart Disease",
      no = "No Heart Disease"
    )
  )
```

```{r predFac}
## Set predictions as factors
heartPredictionsEvan$rpart2_pred <- as.factor(heartPredictionsEvan$rpart2_pred)
```

```{r mergeColumn}
# Merge supervision column into predictions data frame
heartPredictionsEvan <- cbind(
  HeartDisease = testingDataEvan$HeartDisease,
  heartPredictionsEvan
)
```

```{r matrixOne, fig.pos = "H", echo=FALSE, message=FALSE}
heartPredictionsEvan$HeartDisease <- factor(heartPredictionsEvan$HeartDisease)
# Build confusion matrix for second rpart model
conf_mat(
  data = heartPredictionsEvan,
  truth = HeartDisease,
  estimate = rpart2_pred
)$table %>%
  kable(
    col.names = c("Heart Disease", "No Heart Disease"),
  digits = 3,
  booktabs = TRUE,
  align = "c",
  table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(
    full_width = FALSE
  )%>%
  kable_styling(latex_options = c("HOLD_position"))
```

```{r accSensSpec}
# Build a data frame with model metrics
heartPredsEvan <- heartPredictionsEvan %>%
  dplyr::select(HeartDisease, contains("_pred")) %>%
  pivot_longer(
    cols = !c(HeartDisease),
    names_to = "model",
    values_to = "prediction"
  )

accuracy <- heartPredsEvan %>%
  group_by(model) %>%
  accuracy(
    truth = HeartDisease,
    estimate = prediction
  )

sensitivity <- heartPredsEvan %>%
  group_by(model) %>%
  sensitivity(
    truth = HeartDisease,
    estimate = prediction,
    event_level = "second"
  )

specificity <- heartPredsEvan %>%
  group_by(model) %>%
  specificity(
    truth = HeartDisease,
    estimate = prediction,
    event_level = "second"
  )

modelMetricsEvan <- bind_rows(
  accuracy,
  sensitivity,
  specificity
)
```

```{r modelMet, fig.pos = "H", echo=FALSE, message=FALSE}
# Make a nice looking table of model metrics
modelMetricsEvan %>%
  dplyr::select(model, .metric, .estimate) %>%
  pivot_wider(
    id_cols = model,
    names_from = .metric,
    values_from = .estimate
  ) %>%
  kable(
    digits = 3,
    booktabs = TRUE,
    align = "c",
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(
    full_width = FALSE
  )%>%
  kable_styling(latex_options = c("HOLD_position"))
```

```{r randFor}
# Using randomForest to use an ensemble method
# library(randomForest)
trainingDataEvan$HeartDisease <- as.factor(trainingDataEvan$HeartDisease)
heartForest1 <- randomForest(
  formula = HeartDisease ~ Age + Sex + RestingBP + Cholesterol + ExerciseAngina + ChestPainType,
  data = trainingDataEvan,
  ntree = 1000,
  mtry = 3,
  importance = TRUE,
  do.trace = FALSE, 
  keep.forest = TRUE
)
```

```{r plotOne, fig.pos = "H",echo=FALSE, message=FALSE}
# Create a line plot of OOB Error and Misclassification Rates
as.data.frame(heartForest1$err.rate) %>%
  mutate(
    Tree = row_number(),
    .before = OOB
  ) %>%
  pivot_longer(
    cols = !Tree,
    names_to = "Type",
    values_to = "Error"
  ) %>%
  ggplot(
    mapping = aes(
      x = Tree,
      y = Error,
      color = Type,
      linetype = Type
    )
) +
  geom_path() +
  theme_bw() +
  scale_linetype_manual(values = c("dashed", "dotted", "solid"))
```

```{r importance, fig.pos = "H", echo=FALSE, message=FALSE}
# Display attribute importance in a table
importance(heartForest1) %>%
  kable(
    digits = 3,
    booktabs = TRUE,
    align = "c",
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(
    full_width = FALSE
  )%>%
  kable_styling(latex_options = c("HOLD_position"))
```

```{r plotImp, fig.pos = "H",echo=FALSE, message=FALSE}
# Attribute Importance Plots

varImpPlot(
  x = heartForest1,
  main = "Classifying Graduated/Not Graduated Students"
)

# Predict new observations
testingResultsEvan <- testingDataEvan
testingResultsEvan$predicted <- predict(
  object = heartForest1,
  newdata = testingDataEvan,
  type = "response"
)
```

```{r matrixTwo, fig_pos = "H", echo=FALSE, message=FALSE}
testingResultsEvan$HeartDisease <- factor(testingResultsEvan$HeartDisease)
# Build Confusion Matrix
conf_mat(
  data = testingResultsEvan,
  truth = HeartDisease,
  estimate = predicted
)$table %>%
  kable(
    col.names = c("Prediction/Supervision", "Heart Disease", "No Heart Disease"),
    digits = 3,
    booktabs = TRUE,
    align = "c",
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(
    full_width = FALSE
  )%>%
  kable_styling(latex_options = c("HOLD_position"))
```

```{r accSensSpec}
# Build a data frame with model metrics
heartTest <- testingResultsEvan %>%
  dplyr::select(HeartDisease, contains("predicted")) %>%
  pivot_longer(
    cols = !c(HeartDisease),
    names_to = "model",
    values_to = "prediction"
  )

accuracy <- heartTest %>%
  group_by(model) %>%
  accuracy(
    truth = HeartDisease,
    estimate = prediction
  )

sensitivity <- heartTest %>%
  group_by(model) %>%
  sensitivity(
    truth = HeartDisease,
    estimate = prediction,
    event_level = "second"
  )

specificity <- heartTest %>%
  group_by(model) %>%
  specificity(
    truth = HeartDisease,
    estimate = prediction,
    event_level = "second"
  )

modelMetricsEvan <- bind_rows(
  accuracy,
  sensitivity,
  specificity
)
```

```{r modelMet, fig.pos = "H", echo=FALSE, message=FALSE}
# Make a nice looking table of model metrics
modelMetricsEvan %>%
  dplyr::select(model, .metric, .estimate) %>%
  pivot_wider(
    id_cols = model,
    names_from = .metric,
    values_from = .estimate
  ) %>%
  kable(
    digits = 3,
    booktabs = TRUE,
    align = "c",
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(
    full_width = FALSE
  )%>%
  kable_styling(latex_options = c("HOLD_position"))
```

```{r change}
testingDataEvan <- as.data.frame(testingDataEvan)
```

```{r grad3}
library(dplyr)
testingDataEvan$HeartDisease <- factor(testingDataEvan$HeartDisease)
# Using randomForest to do training and testing
heartForest3 <- randomForest(
  x = trainingDataEvan[, which(!(names(trainingDataEvan) %in% c("tempID", "HeartDisease")))],
  y = trainingDataEvan$HeartDisease,
  xtest <- testingDataEvan[, which(!(names(testingDataEvan) %in% c("tempID", "HeartDisease")))],
  ytest = testingDataEvan$HeartDisease,
  ntree = 1000, 
  mtry = 3,
  importance = TRUE,
  do.trace = FALSE,
  keep.forest = TRUE
)
```

```{r oobTestError, fig.pos = "H",echo=FALSE, message=FALSE}
# Plot of OOB and Testing Set Errors
bind_cols(
  oob = as.data.frame(heartForest3$err.rate)$OOB,
  test = as.data.frame(heartForest3$test$err.rate)$Test
) %>%
  mutate(
    tree = row_number(),
    .before = oob
  ) %>%
  pivot_longer(
    cols = !tree,
    names_to = "Source",
    values_to = "Error"
  ) %>%
  ggplot(
    mapping = aes(
      x = tree,
      y = Error,
      color = Source,
      linetype = Source
    )
  ) +
  geom_path() +
  theme_bw()
```

# Clustering

## Comparing the results

## Discussion and Limitations
